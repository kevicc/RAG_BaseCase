# RAG_BaseCode
For those interested in actively using RAG with FAISS (Facebook AI Similarity Search) and a top-tier LLM model, here is my first attempt at a base code in Python. While it may fall victim to some of the challenges outlined in “Retrieval-Augmented Generation for Large Language Models: A Survey” for naive models, I have tested this pipeline with two datasets and few models, and its basic ability to respond coherently is quite robust (though no formal evaluations have been conducted). In this particular version of the script, I’ve uploaded the most recent data on waterfront properties surrounding Montreal that are for sale (scraped, translated, and cleaned from publicly available Centris postings) to learn about the real estate landscape, and if there’s a cottage that meets my dream criteria.

How does it work? FAISS performs a similarity search to filter the descriptions of 1.5K properties down to 10 top selections (technically constructed as “chunks of text”). Then, Qwen2.5 responds to a query prompt that is contextualized using the refined data selected. Instead of slowly and manually reading through each posting, I’m letting a few lines of code and powerful AI do the grunt work. Curious what I learned? Try running the script yourselves; the dataset is now public on Hugging Face under the name kpericak/waterfront_centris_nearmontreal_feb2025.
